{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPJm+xktTBrx1Pqs87t6VbM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 0. 라이브러리 로드"],"metadata":{"id":"8ZaKZ_PmfreK"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import math\n","from typing import Callable, Optional\n","from torch import Tensor\n","import torch.nn.functional as F\n","import numpy as np"],"metadata":{"id":"kaCXTwoAfvGm","executionInfo":{"status":"ok","timestamp":1706852374230,"user_tz":-540,"elapsed":4,"user":{"displayName":"‎이주원(호크마교양대학 호크마교양대학)","userId":"04513129207991464839"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#1. PatchTST_layers"],"metadata":{"id":"LJx8mOO5fW_l"}},{"cell_type":"code","source":["class Transpose(nn.Module):\n","  def __init__(self,*dims,contiguous=False):\n","    super().__init__()\n","    self.dims, self.contiguous=dims, contiguous\n","  def forward(self, x):\n","    if self.contiguous: return x.transpose(*self.dims).contiguous()\n","    else: return x.transpose(*self.dims)\n","\n","def get_activation_fn(activation):\n","  if callable(activation): return activation()\n","  elif activation.lower()==\"relu\": return nn.ReLU()\n","  elif activation.lower()==\"gelu\": return nn.GELU()\n","  raise ValueError(f'{activation} is not available. You can use \"relu\", \"gelu\", or a callable')\n","\n","  #decomposition\n","  class moving_avg(nn.Module):\n","    \"\"\"\n","    Moving average block to highlight the trend of time series\n","    \"\"\"\n","    # kernel_size: 이동 평균을 계산할 때 사용되는 윈도우 크기를 정의\n","    # stride: 이동 평균 계산 시의 Stride(간격)을 정의\n","    def __init__(self, kernel_size, stride):\n","      super(moving_avg, self).__init__()#굳이 이런식으로 인자 넘겨야 하나\n","      self.kernel_size=kernel_size\n","\n","      #nn.AvgPool1d를 이용하여 1차원 평균 풀링을 구현. 이동 평균 계산에 사용\n","      self.avg=nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n","\n","    def forward(self, x):\n","      #front 와 end는 필터를 적용함에 따라 감소하는 데이터의 양을\n","      #채우기 위한 padding의 역할\n","      front=x[:,0:1,:].repeat(1,(self.kernel_size-1)//2,1)\n","      end=x[:,-1:,:].repeat(1, (self.kernel_size-1)//2,1)\n","\n","      #만들어진 Padding과 원래 데이터를 결합한다.\n","      x=torch.cat([front, x, end],dim=1)\n","\n","      #Signal의 차원을 변환하고, nn.AvgPool1d를 이용하여 avg 걔산\n","      x=self.avg(x.permute(0,2,1))\n","      #차원을 원래대로 변환하여 Avg를 구한다.\n","      x=x.permute(0,2,1)\n","      return x\n","\n","class series_decomp(nn.Module):\n","      \"\"\"\n","      Time Series Data에 대해서\n","      Moving Average Decomposition을\n","      수행하기 위한 Class 선언\n","      \"\"\"\n","      def __init__(self, kernel_size):\n","        super(series_decomp, self).__init__()\n","        self.moving_avg=moving_avg(kernel_size, stride=1)\n","\n","      def forward(self, x):\n","        #moving mean: nn.Module로 선언된 moving_avg를 호출하고\n","        #입력 데이터의 이동평균을 계산한다.\n","        moving_mean=self.moving_avg(x)\n","\n","        #원래 데이터에서 이동평균을 빼서 잔차를 구한다.\n","        res=x-moving_mean\n","\n","        #잔차와 이동평균을 반환한다.\n","        return res, moving_mean\n","      #pos_encoding\n","      def PositionalEncoding(q_len, d_model, normalize=True):\n","        pe=torch.zeros(q_len, d_model)\n","        position=torch.arange(0,q_len).unsqueeze(1) #내용 변형 없이 차원 1 증가\n","        div_term=torch.exp(torch.arange(0,d_model,2)*-(math.log(10000.0)/d_model))\n","        pd[:,0::2]=torch.sin(position*div_term)\n","        pd[:,1::2]=torch,cos(position*div_term)\n","        if normalize:\n","          pe=pe-pe.mean()\n","          pe=pe/(pe.std()*10) #곱하기 10은 왜 하는 거임?\n","        return pe\n","\n","      sinCosPosEncoding=PositionalEncoding\n","\n","      def Coord2dPosEncoding(q_lem, d_model, exponential=False, normalize=True, eps=1e-3, verbose=False):\n","        x=.5 if exponential else 1\n","        i=0\n","        for i in range(100):\n","          cpe=2*(torch.linspace(0,1,q_len).reshape(-1,1)**x)*(torch.linspace(0,1,d_model).reshape(1,-1)**x)-1\n","          #0-1사이를 특정 개수만큼 나누고 원하는 차원으로 변형시켜주기\n","          print(f'{i:s.0f} {x:5.3f} {cpe.mean(): +6.3f}',verbose)\n","          if abs(cpe.mean())<=eps:break #평균값이 충분히 0에 가까워지면 중단\n","          elif cpe.mean()>eps:x+=.001\n","          else: x-=.001\n","          i+=1\n","\n","        if normalize:\n","         cpe=cpe-cpe.mean()\n","         cpe=cpe/(cpe.std()*10)\n","        return cpe\n","\n","      def Coord1dPosEncoding(q_len, exponential=False, normalize=True):\n","        cpe=(2*(torch.linspace(0,1,q_len).reshape(-1,1)**(.5 if exponential else 1))-1)\n","        if normalize:\n","          cpe=cpe-cpe.mean()\n","          cpe=cpe/(cpe.std()*10)\n","        return cpe\n","\n","      def positional_encoding(pe, learn_pe, q_len, d_model):\n","        #Positional encoding\n","        if pe==None:\n","          W_pos=torch.empty((q_len,d_model)) #pe=None and learn_pe=False can be used to measure impact of pe\n","          nn.init.uniform_(W_pos, -0.02,0.02)\n","          learn_pe=Fale\n","        elif pe=='zero':\n","          W_pos=torch.empty((q_len,1))\n","          nn.init.uniform_(W_pos, -0.02, 0.02)\n","        elif pe=='zeros':\n","          W_pos=torch.empty((q_len, d_model))\n","          nn.init.uniform_(W_pos, -0.02, 0.02)\n","        elif pe=='normal' or pe=='gauss':\n","          W_pos=torch.zeros((q_len, 1))\n","          torch.nn.init.normal_(W_pos, mean=0.0, std=0.1)\n","        elif pe=='uniform':\n","          W_pos=torch.zeros((q_len,1))\n","          nn.init.uniform_(W_pos, a=0.0,b=0.1)\n","        elif pe=='lin1d':W_pos=Coord1dPosEncoding(q_len, exponential=False, normalize=True)\n","        elif pe=='exp1d':W_pos=Coor1dPosEncoding(q_len, exponential=True, normalize=True)\n","        elif pe=='lin2d':W_pos=Coor2dPosEncoding(q_len, d_model, exponential=False, normalize=True)\n","        elif pe=='ex2d':W_pos=Coor2dPosEncoding(q_len, d_model, exponential=True, normalize=True)\n","        elif pe=='sincos':W_pos=PositionalEncoding(q_len, d_model, normalize=True)\n","        else: raise ValueError(f\"{pe}is not a valid pe (positional encoder, Available types: 'gauss'=='normal','zoros','zero','uniform', 'lin1d', 'ex1d','lin23','ex2d','sincos','None.')\")\n","        return nn.Parameter(W_pos, requires_grad=learn_pe)\n","\n","\n"],"metadata":{"id":"N91xmUOofpJF","executionInfo":{"status":"ok","timestamp":1706852377993,"user_tz":-540,"elapsed":5,"user":{"displayName":"‎이주원(호크마교양대학 호크마교양대학)","userId":"04513129207991464839"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":[".contiguous(): transpose로 인해 변경된 텐서의 메모리 레이아웃이 연속적이지 않게 될 수 있기 때문에, 이를 다시 연속적인 메모리 레이아웃으로 만듦.  \n","callable(object): 전달받은 object 인자가 호출 가능한지 여부  \n",".lower(): 소문자로 바꾸기  \n","torch.arange(0, d_model, 2): 이 부분은 0부터 시작하여 d_model에 도달할 때까지 2씩 증가하는 숫자들로 1차원 텐서를 생성  \n","verbose가 True일 때만 실행되며, i, x, cpe.mean() 값을 지정된 형식에 따라 출력합니다.  \n","nn.init.uniform_(W_pos, -0.02, 0.02):\n","텐서의 모든 값을 균일 분포를 따르는 난수로 초기화.\n","이 경우, 모든 값은 -0.02와 0.02 사이의 범위에서 무작위로 선택. _ 접미사는 이 연산이 W_pos 텐서 자체를 변경(in-place)한다는 것을 나타냅니다."],"metadata":{"id":"BXAiACK0mu1T"}},{"cell_type":"markdown","source":["# 2. RevIN"],"metadata":{"id":"NP9HQW5qLyUX"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class RevIN(nn.Module):\n","  def __init__(self,num_features: int, eps=1e-5, affine=True, subtract_last=False):\n","    \"\"\"\n","    :param num_features: the number of features or channels\n","    :param eps: a value added for numerical stability\n","    :param affine: if True, RevIN has learnable affine parameters\n","    \"\"\"\n","    super(RevIN,self).__init__()\n","    self.num_features=num_features\n","    self.eps=eps\n","    self.affine=affine\n","    self.subtract_last=subtract_last\n","    if self.affine:\n","      self._inint_params()\n","\n","  def forward(self, x, mode:str):\n","    if mode=='norm':\n","      self._get_statistics(x)\n","      x=self._normalize(x)\n","    elif mode=='dnorm':\n","      x=self._denormalize(X)\n","    else: raise NotImplementedError\n","    return x\n","\n","  def _init_params(self):\n","    #initialize RevIN params:\n","    self.affine_weight=nn.Parameter(torch.ones(self.num_features))\n","    self.affine_bias=nn.Parameter(torch.zeros(self.num_features))\n","\n","  def _get_statistics(self, x):\n","    dim2reduce=tuple(range(1,x.ndim-1))\n","    if self.subtract_last:\n","      self.last=x[:,-1,:].unsqueeze(1)\n","    else:\n","      self.mean=torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n","    self.stdev=torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False)+self.eps).detach()\n","\n","  def _normalize(self, x):\n","      if self.subtract_last:\n","          x = x - self.last\n","      else:\n","          x = x - self.mean\n","          x = x / self.stdev\n","      if self.affine:\n","           x = x * self.affine_weight\n","           x = x + self.affine_bias\n","      return x\n","  def _denormalize(self, x):\n","      if self.affine:\n","         x = x - self.affine_bias\n","         x = x / (self.affine_weight + self.eps*self.eps)\n","      x = x * self.stdev\n","      if self.subtract_last:\n","         x = x + self.last\n","      else:\n","         x = x + self.mean\n","      return x\n"],"metadata":{"id":"RPBNUzaxMuGK","executionInfo":{"status":"ok","timestamp":1706852381856,"user_tz":-540,"elapsed":306,"user":{"displayName":"‎이주원(호크마교양대학 호크마교양대학)","userId":"04513129207991464839"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["#3. Backbone"],"metadata":{"id":"tfmN-PKIVLPt"}},{"cell_type":"code","source":["class PatchTST_backbone(nn.Module):\n","  def __init__(self, c_in:int, context_window:int, target_window:int, patch_len:int, stride:int, max_seq_len:Optional[int]=1024,\n","               n_layers:int=3, d_model=128, n_heads=16, d_k:Optional[int]=None, d_v:Optional[int]=None,\n","               d_ff:int=256, norm:str='BatchNorm',attn_dropout:float=0., dropout:float=0., act:str=\"gelu\", ley_padding_mask:bool='auto',\n","               pe:str='zeros', learn_pe:bool=True, fc_dropout:float=0., head_dropout = 0, padding_patch = None,\n","              pretrain_head:bool=False, head_type = 'flatten', individual = False, revin = True, affine = True, subtract_last = False,\n","              verbose:bool=False, **kwargs):\n","    super().__init__()\n","\n","    #RevIn\n","    self.revin=revin\n","    if self.revin: self.revin_layer=RevIN\n","\n","    #Patching\n","    self.patch_len=patch_len\n","    self.stride=stride\n","    self.padding_patch=padding_patch\n","    patch_num=int((context_window-patch_len)/stride+1)\n","    if padding_patch=='end':\n","      self.padding_patch_layer=nn.ReplicationPad1d((0,stride))\n","      patch_num+=1\n","      #can be modified to general case\n","\n","    #Backbone\n","    self.backbone=TSTiEncoder(c_in, patch_num=patch_num, patch_len=patch_len, max_seq_len=max_seq_len,\n","                                n_layers=n_layers, d_model=d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff,\n","                                attn_dropout=attn_dropout, dropout=dropout, act=act, key_padding_mask=key_padding_mask, padding_var=padding_var,\n","                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=pre_norm, store_attn=store_attn,\n","                                pe=pe, learn_pe=learn_pe, verbose=verbose, **kwargs)\n","\n","    #Head\n","    self.head_nf=d_model*patch_num\n","    self.n_vars=c_in\n","    self.pretrain_head=pretrain_head\n","    self.head_tupe=head_type\n","    self.individual=individual\n","\n","    if self.pretrain_head:\n","      self.head=self.create_pretrain_head(self.head_nf, c_in, fc_dropout)\n","    elif head_type=='flatten':\n","      self.head=Flatten_Head(self,individual, self.n_vars, self.head_nf,target_window, head_dropout=head_dropout)\n","\n","    #z: batch size* nvars(numbers of variables)*L(sequence length)\n","    #넘겨주고 나서 나중에 patching 으로 잘라서?\n","\n","    def forward(self, z):\n","      #norm\n","      if self.revin:\n","        z=z.permute(0,2,1) #잠시 위치 바꿔주기\n","        z=self.revin_layer(z,'norm')\n","        z=z.permute(0,2,1)\n","\n","      #do patchinging\n","      if self.padding_patch=='end':\n","        z=self.padding_patch_layer(z)\n","\n","      #(bs, 7, N, P)\n","      z=z.unfole(simension=-1, size=self.patch_len, step=self.stride)\n","\n","      #(bs, 7, P,N)\n","      z=z.permute(0,1,3,2)\n","\n","      #model\n","      z=self.backbone(z)\n","      z=self.head(z)\n","\n","      #denorm :앞에서 norm 시켜줬기 때문에 다시 나의 데이터로 돌아오기 위함\n","      if self.revin:\n","\n","        z=z.permute(0,2,1)\n","        z=self.revin_layer(z, 'denorm')\n","        z=z.permute(0,2,1)\n","      return z\n","\n","    def create_pretrain_head(self, head_nf, vars, dropout):\n","      return nn.Sequential(nn.Dropout(dropout),\n","                           nn.Conv1d(head_nf, vars, 1))\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ZajSPgpOVQN_","executionInfo":{"status":"ok","timestamp":1706853037503,"user_tz":-540,"elapsed":306,"user":{"displayName":"‎이주원(호크마교양대학 호크마교양대학)","userId":"04513129207991464839"}}},"execution_count":10,"outputs":[]}]}