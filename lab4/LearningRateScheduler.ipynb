{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPzjoaOROrPq7s2iLB5+s0O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Optimizer(옵티마이저)\n","모델의 오류를 줄이기 위해 모델 매개변수를 조정하는 과정.  \n","1. 옵티마이저 등록  \n","`optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate`  \n","2.변화도 명시적으로 0 설정  \n","`optimizer.zero_grad()`  \n","3. 예측 손실 역전파  \n","`loss.bachwards()`  \n","4. 역전파 단계에서 수집된 변화도로 매개변수 조정   \n","`optimizer.step()`  \n","매개변수 = 매개변수 - 학습률 * 그래디언트"],"metadata":{"id":"hfUi80aSG4hw"}},{"cell_type":"code","source":["# 기본 라이브러리 설치\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim"],"metadata":{"id":"zsHEjIfiMRJG","executionInfo":{"status":"ok","timestamp":1705675694642,"user_tz":-540,"elapsed":268,"user":{"displayName":"‎이주원(호크마교양대학 호크마교양대학)","userId":"04513129207991464839"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Learning Rate Scheduler  \n","learning rate: gradient 보폭  \n","Scheduler가 이것을 변경시켜주기도  \n","`optimizer=torch.optim.SGD(model.parameters(),lr=0.01)` 기본적으로 optimizer 넣어주고"],"metadata":{"id":"rllfVhJCKe9s"}},{"cell_type":"code","source":["optimizer=torch.optim.SGD(model.parameters(),lr=0.01)"],"metadata":{"id":"vcI32jRwMa-U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##LambdaLR"],"metadata":{"id":"yWm46tadLduz"}},{"cell_type":"markdown","source":["`scheduler=optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch:0.95**epoch)`"],"metadata":{"id":"554oV0FpLloW"}},{"cell_type":"code","source":[],"metadata":{"id":"Y2UA3RWMMA0b"},"execution_count":null,"outputs":[]}]}